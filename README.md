# Machine Learning Platform Engineer

O projeto consiste em implementar uma arquitetura completa que consome a Punk Api no
[endpoint](https://api.punkapi.com/v2/beers/random) e ingere em um Kinesis Stream que ter√° 2 consumidores.
Com os dados processados, treinar um modelo de machine learning e integrar √† arquitetura.



Tabela de conte√∫dos
=================
<!--ts-->
   * [Sobre](#sobre)
   * [Arquitetura](#arquitetura)
   * [Pr√©-Requisitos](#pre-requisitos)
   * [Instala√ß√£o](#instalacao)
   * [Como executar o projeto](#executar-terraform)
   * [Tecnologias](#tecnologias)
   * [Execu√ß√£o do Desafio](#execucao_desafio)
   * [Autor](#autor)
   * [Licen√ßa](#licenca)
   * [Refer√™ncias](#referencias)
<!--te-->

<h4 align="center"> 
	üöß üöÄ Em constru√ß√£o...  üöß
</h4>


### Features

- [x] Levantamento da arquitetura sem integra√ß√£o do modelo
- [ ] Divis√£o dos dados em: treino, valida√ß√£o, test para SageMaker
- [ ] Cria√ß√£o dos scripts Terraform para SageMaker, API GateWay e Lambda que invoca o Endpoint
- [ ] Cria√ß√£o dos scripts Terraform
- [ ] Desenho da nova arquitetura com a integra√ß√£o do modelo 



# <a name="sobre"><a/> Sobre

O presente projeto tem como objetivo implementar uma arquitetura completa que consome a [Punk API](https://punkapi.com/) no endpoint
https://api.punkapi.com/v2/beers/random e ingere em um Kinesis Stream que ter√° 2 consumidores. 

Para isso voc√™ ser√° necess√°rio configurar:

   1. Um CloudWatch Event que dispara a cada 5 minutos uma fun√ß√£o Lambda para alimentar o Kinesis Stream que ter√° como sa√≠da:
      * Um Firehose agregando todas as entradas para guardar em um bucket S3 com o nome de `raw`.

      * Outro Firehose com um Data Transformation que pega somente os `id`, `name`, `abv`, `ibu`, `target_fg`, `target_og`, `ebc`, `srm` e `ph` das cervejas e guarda em um outro bucket S3 com o nome de `cleaned` em formato **csv**.

   2. Crie uma tabela com os dados do bucket `cleaned`.

   3. Com base nos dados da tabela `cleaned`, treine um modelo de machine learning que classifique as cervejas em seus respectivos ibus.


# <a name="arquitetura"><a/> üè¢ Arquitetura

<h1 align="center">
  <img alt="Arquitetura" title="Arquitetura" src="./images/arquitetura_original.png" />
</h1>


# <a name="pre-requisitos"><a/> ‚òëÔ∏è Pr√©-Requisitos


#### Criar conta na AWS
   * Antes de come√ßar, voc√™ vai precisar ter uma conta na AWS, para isso acesse [AWS Console](https://aws.amazon.com/).

#### Cria√ß√£o de usu√°rio/grupo no AWS IAM

   1. Entre no console da AWS e pesquise pelo servi√ßo **IAM**;
   2. No menu √† esquerda clique em "users";
   3. Clique no bot√£o "add user";
      * Insira um nome para o usu√°rio, no meu caso foi `admin`;
      * Em `Select AWS access type` marque a primeira caixa `Programmatic access Enables an access key ID and secret access key for the AWS API, CLI, SDK, and other development tools.`;
      * Clique em `Next:Permissions`;
      * Caso n√£o tenha nenhum grupo j√° criado, clique em `create group`;
      * Na janela que abrir, insira um nome para o grupo, no meu caso foi `admin_group`;
      * Em `Filter Policies` marque a op√ß√£o `AdministratorAccess` e clique em `Create group`;
      * Clique em `Next: Tags`;
      * Em `Add tags (optional)` n√£o √© necess√°rio nenhum procedimento, apenas clique em `Next: Review`;
      * Ser√° apresentado um sum√°rio do usu√°rio e grupo que ser√£o criados, confira as informa√ß√µes e se estiverem de acordo com o desejado clique em `Create user`.


#### Cria√ß√£o de Acess key

Ap√≥s criado o usu√°rio no passo anterior, realize as seguintes etapas para criar as `acess_key`:

   1. Entre no console da AWS e pesquise pelo servi√ßo **IAM**;
   2. No menu √† esquerda clique em "users";
   3. Clique no usu√°rio que voc√™ criou;
   4. Na janela que abrir, clique em `Security credentials`;
      * Clique em `Create acess key`;
      * As chaves de acesso ser√£o geradas e dever√° clicar para salvar o arquivo, pois a secret n√£o ser√° apresentada novamente.



# <a name="instalacao"><a/> üë®‚Äçüíª Instala√ß√£o

#### Instala√ß√£o e Configura√ß√£o do AWS CLI

   1. Neste projeto, estou utilizando o sistema operacional Linux. Utilize o seguinte roteiro para a instala√ß√£o [instala√ß√£o AWS CLI](https://linuxhint.com/install_aws_cli_ubuntu/)
   2. Com o AWS CLI instalado, voc√™ dever√° configurar suas credenciais:
   ```bash
   # Execute o comando abaixo para iniciar a configura√ß√£o
   $ aws configure
   ```
    * Insira a `Acess Key` e tecle Enter;
    * Insira a `Secret Key` e tecle Enter;
    * Insira o c√≥digo da regi√£o, no meu caso √© `sa-east-1`;
    * No valor formato de sa√≠da, pode deixar `None` e tecle Enter.

#### Instala√ß√£o e Configura√ß√£o do Terraform

   1. Clique no link para baixar o Terraform de acordo com seu sistema operacional [download Terraform](https://www.terraform.io/downloads.html):
      * No meu caso, estou utilizando Linux 64-bit, ap√≥s clicar no link um arquivo ser√° baixado.
   2. Descompacte o arquivo e execute os comandos abaixo: 
      * [Roteiro de Instala√ß√£o](https://learn.hashicorp.com/tutorials/terraform/install-cli?in=terraform/aws-get-started)
   ```bash
    $ echo $PATH

   # Mova o arquivo terraform para o resultado do echo $PATH no comando anterior
   $ mv ~/Downloads/terraform /usr/local/bin/

   # Verifique a instala√ß√£o do Terraform
   $ terraform -help
   ```

# <a name="executar-terraform"><a/> üöÄ Como executar o projeto (Terraform)

Navegue at√© o diret√≥rio onde os scripts terraform est√£o para executar os passos abaixo:

```bash
# Inicialize o projeto.
$ terraform init

# Exibe um plano dos servi√ßos que ser√£o criados.
$ terraform plan

# Caso queira salvar o plano de execu√ß√£o dos servi√ßos, substitua "path" por um caminho v√°lido.
$ terraform plan -out=path 

# Realiza a cria√ß√£o dos servi√ßos nos scripts extens√£o .tf. 
# Quando o Terraform solicitar que voc√™ confirme, digite yes e pressione Enter.
$ terraform apply

# Para excluir os servi√ßos, execute terraform destroy.
$ terraform destroy
```


# <a name="tecnologias"><a/> üõ† Tecnologias

As seguintes linguagens foram usadas na constru√ß√£o do projeto:

- [Python](https://www.python.org/)
- [Terraform](https://www.terraform.io/)

#### Serverless

- [AWS Lambda](https://aws.amazon.com/en/lambda/)
- [Amazon Kinesis](https://aws.amazon.com/en/kinesis/)
- [Amazon Kinesis Data Firehose](https://aws.amazon.com/en/kinesis/data-firehose/)
- [AWS Glue](https://aws.amazon.com/en/glue/)

#### Plataforma de Machine Learning

- [Amazon SageMaker](https://aws.amazon.com/en/sagemaker/)

#### Scheduler e monitoramento de servi√ßos

- [Amazon Cloudwatch](https://aws.amazon.com/en/cloudwatch/)


#### API REST

 - [Amazon API Gateway](https://aws.amazon.com/en/api-gateway/)


# <a name="execucao_desafio"><a/> ‚ùïExecu√ß√£o do Desafio

Siga os passos abaixo para a entrega do desafio:

   1. Criar uma conta gratuita na `AWS`.

   2. Voc√™ deve utilizar `Terraform` para construir a arquitetura de uma maneira reproduz√≠vel em outras contas.

   3. Todas as fun√ß√µes `Lambdas` devem ser desenvolvidas em `Python` assim como o modelo de machine learning.

   4. O modelo de machine learning deve ser apresentado em um Jupyter Notebook, local ou remoto. O arquivo do notebook estar no reposit√≥rio do github.

   5. B√¥nus (n√£o obrigat√≥rio): Integre o modelo de machine learning em sua arquitetura.


## Arquitetura da implementa√ß√£o

<h1 align="center">
  <img alt="Arquitetura" title="Arquitetura" src="./images/arquitetura_final.png" />
</h1>

### **Legenda**

<h1 align="left">
  <img alt="Arquitetura" title="Arquitetura" src="./images/legenda_arquitetura_final.png" />
</h1>

### Detalhes da implementa√ß√£o

<span style="color:red">teste</span>
**Item 2. Para acessar o diret√≥rio onde est√£o os scripts `Terraform` clique [aqui](https://github.com/ldynczuki/MLPlatformEngineer/tree/main/code/terraform)**

**Item 3. Para acessar o diret√≥rio onde est√£o as fun√ß√µes `Lambdas` desenvolvidas em `Python` clique [aqui](https://github.com/ldynczuki/MLPlatformEngineer/tree/main/code/terraform)**:
* Para a implementa√ß√£o do desafio, as fun√ß√µes `Lambda` foram compactadas em formato .zip e possuem os seguintes nomes: `lambda_data_processing.zip`, `lambda_data_processing.zip` e `lambda_call_endpoint.zip`.

**Item 4. Treinamento do modelo de machine learning (local):**
* Conforme apresentado o item 4., foi realizado o treinamento de um modelo de machine learning (local), o qual foi utilizado o Jupyter Notebook, onde √© poss√≠vel acess√°-lo clicando [aqui](https://github.com/ldynczuki/MLPlatformEngineer/blob/main/code/models/local-notebook/model-ml-platform.ipynb). 
* Nesta etapa, criei um objeto client do `AWS Glue` para encontrar a tabela `cleaned` e a localiza√ß√£o da fonte de dados transformados `bucket S3`. 
* Ap√≥s encontrar a localiza√ß√£o dos dados, criei um DataFrame dos dados do `bucket S3` e iniciei a an√°lise explorat√≥rio dos dados, onde foi poss√≠vel verificar que a feature `abv` √© a que possui maior correla√ß√£o com a nossa coluna target `ibu`. Deste modo, irei realizar 2 treinamentos, o primeiro utilizando todas as features e outro treinamento apenas com a feature `abv` e irei comparar os resultados finais.
* Antes do treinamento do modelo √© essencial realizar o pr√©-processamento dos dados, onde foram eliminadas as colunas n√£o utilizadas para o treinamento, tais como `id` e `name`, apliquei tamb√©m uma convers√£o destes dados para **numpy array** com o tipo de dados float32 e, por fim, a divis√£o da base de dados em treinamento e teste, em uma propor√ß√£o de 80% e 20%, respectivamente.
* Com os dados pr√©-processados, realizei o treinamento do modelo utilizando a t√©cnica de regress√£o linear m√∫ltipla e simples.
* Posteriormente o treino dos modelos, foi realizada a avalia√ß√£o dos modelos utilizando as seguintes m√©tricas: **MAE** (_Mean Absolute Error_), **MSE** (_Mean Squared Error_), **RMSE** (_Root Mean Squared Error_) e	**R2 Square**.
* Foi poss√≠vel observar no DataFrame final dos resultados que o modelo de regress√£o linear m√∫ltipla obteve um melhor resultado.
* √â importante salientar que, com a baixa quantidade de amostras distintas n√£o foi poss√≠vel obter um bom resultado durante o treinamento e que tamb√©m existem outras t√©cnicas de machine learning que podem alcan√ßar melhores m√©tricas. Todavia, o objetivo deste treinamento foi acessar os metadados do `AWS Glue`, obter a localiza√ß√£o e os dados no `bucket S3` e realizar o treinamento.




# <a name="autor"><a/> ü§ì Autor

Lucas Dynczuki

Entre em contato! üíö

[![Linkedin Badge](https://img.shields.io/badge/-Lucas-blue?style=flat-square&logo=Linkedin&logoColor=white&link=https://www.linkedin.com/in/lucasdynczuki/)](https://www.linkedin.com/in/lucasdynczuki/) 
[![Outlook Badge](https://img.shields.io/badge/-lucas.dynczuki@outlook.com-blue?style=flat-square&logo=Outlook&logoColor=white&link=mailto:lucas.dynczuki@outlook.com)](mailto:lucas.dynczuki@outlook.com)


# <a name="licenca"><a/>  üìù Licen√ßa

[![GitHub license](https://img.shields.io/github/license/ldynczuki/MLPlatformEngineer)](https://github.com/ldynczuki/MLPlatformEngineer/blob/main/LICENSE)


Este projeto esta sobe a licen√ßa [MIT](./LICENSE).


# <a name="referencias"><a/>  üìö Refer√™ncias

https://aws.amazon.com/en/
https://aws.amazon.com/en/cli/
https://aws.amazon.com/en/lambda/
https://aws.amazon.com/en/kinesis/data-streams/
https://aws.amazon.com/en/kinesis/data-firehose/
https://aws.amazon.com/en/glue/
https://aws.amazon.com/pt/cloudwatch/
https://aws.amazon.com/en/sagemaker/
https://www.terraform.io/downloads.html
https://learn.hashicorp.com/tutorials/terraform/install-cli?in=terraform/aws-get-started
https://learn.hashicorp.com/tutorials/terraform/aws-build?in=terraform/aws-get-started
https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/lambda_function
https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/kinesis_stream
https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/kinesis_firehose_delivery_stream
https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/glue_catalog_database
https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/glue_catalog_table
https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudwatch_event_rule
https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudwatch_event_target
https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_policy
https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_role
https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_role_policy_attachment
https://linuxhint.com/install_aws_cli_ubuntu/
https://michael-timbs.medium.com/linear-regression-with-aws-sagemaker-15feefb19342
https://towardsdatascience.com/using-aws-sagemakers-linear-learner-to-solve-regression-problems-36732d802ba6
https://aws.amazon.com/pt/blogs/machine-learning/creating-a-machine-learning-powered-rest-api-with-amazon-api-gateway-mapping-templates-and-amazon-sagemaker/
https://aws.amazon.com/pt/blogs/machine-learning/call-an-amazon-sagemaker-model-endpoint-using-amazon-api-gateway-and-aws-lambda/
https://medium.com/analytics-vidhya/invoke-an-amazon-sagemaker-endpoint-using-aws-lambda-83ff1a9f5443
https://medium.com/@gisely.alves/visualiza%C3%A7%C3%A3o-de-dados-com-seaborn-2fd0defd9adb
https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html